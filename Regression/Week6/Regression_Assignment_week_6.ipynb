{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, 'sqft_living15':float, \n",
    "              'grade':int, 'yr_renovated':int, 'price':float, 'bedrooms':float, 'zipcode':str, \n",
    "              'long':float, 'sqft_lot15':float, 'sqft_living':float, 'floors':float, 'condition':int, \n",
    "              'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sales = pd.read_csv(\"~/Desktop/ML_Washington/WashingtonML/Regression/Week6/kc_house_data_small.csv\", dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"~/Desktop/ML_Washington/WashingtonML/Regression/Week6/kc_house_data_small_train.csv\", dtype = dtype_dict)\n",
    "test = pd.read_csv(\"~/Desktop/ML_Washington/WashingtonML/Regression/Week6/kc_house_data_small_test.csv\", dtype = dtype_dict)\n",
    "validation = pd.read_csv(\"~/Desktop/ML_Washington/WashingtonML/Regression/Week6/kc_house_data_validation.csv\", dtype = dtype_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_sframe, features, output):\n",
    "    data_sframe['constant'] = 1 # this is how you add a constant column to an SFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_SFrame given by the features list into the SFrame features_sframe (now including constant):\n",
    "    features_sframe = data_sframe[features]\n",
    "    # the following line will convert the features_SFrame into a numpy matrix:\n",
    "    feature_matrix = features_sframe.to_numpy()\n",
    "    # assign the column of data_sframe associated with the output to the SArray output_sarray\n",
    "    output_sarray = data_sframe[output]\n",
    "    # the following will convert the SArray into a numpy array by first converting it to a list\n",
    "    output_array = output_sarray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all of the numerical inputs listed in `feature_list`, transform the training, test, and validation SFrames into Numpy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_list = ['bedrooms',  \n",
    "                'bathrooms',  \n",
    "                'sqft_living',  \n",
    "                'sqft_lot',  \n",
    "                'floors',\n",
    "                'waterfront',  \n",
    "                'view',  \n",
    "                'condition',  \n",
    "                'grade',  \n",
    "                'sqft_above',  \n",
    "                'sqft_basement',\n",
    "                'yr_built',  \n",
    "                'yr_renovated',  \n",
    "                'lat',  \n",
    "                'long',  \n",
    "                'sqft_living15',  \n",
    "                'sqft_lot15']\n",
    "features_train, output_train = get_numpy_data(train, feature_list, 'price')\n",
    "features_test, output_test = get_numpy_data(test, feature_list, 'price')\n",
    "features_valid, output_valid = get_numpy_data(validation, feature_list, 'price')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In computing distances, it is crucial to normalize features. Otherwise, for example, the `sqft_living` feature (typically on the order of thousands) would exert a much larger influence on distance than the `bedrooms` feature (typically on the order of ones). We divide each column of the training feature matrix by its 2-norm, so that the transformed column has unit norm.\n",
    "\n",
    "IMPORTANT: Make sure to store the norms of the features in the training set. The features in the test and validation sets must be divided by these same norms, so that the training, test, and validation sets are normalized consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_features(features):\n",
    "    norms = np.linalg.norm(features, axis =0)\n",
    "    normalized_features = features/norms\n",
    "    return (normalized_features, norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, norms = normalize_features(features_train) # normalize training set features (columns)\n",
    "features_test = features_test / norms # normalize test set by training set norms\n",
    "features_valid = features_valid / norms # normalize validation set by training set norms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute multiple distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, to do nearest neighbor regression, we need to compute the distance between our query house and *all* houses in the training set.  \n",
    "\n",
    "To visualize this nearest-neighbor search, let's first compute the distance from our query house (`features_test[0]`) to the first 10 houses of the training set (`features_train[0:10]`) and then search for the nearest neighbor within this small set of houses.  Through restricting ourselves to a small set of houses to begin with, we can visually scan the list of 10 distances to verify that our code for finding the nearest neighbor is working.\n",
    "\n",
    "Write a loop to compute the Euclidean distance from the query house to each of the first 10 houses in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5527, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.00775643,  0.00602491,  0.00459184,  0.00321036,\n",
       "        0.0085295 ,  0.        ,  0.        ,  0.0116321 ,  0.01042901,\n",
       "        0.00529699,  0.        ,  0.0131892 ,  0.        ,  0.01350096,\n",
       "       -0.01345359,  0.0174884 ,  0.00327015])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_train[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01345102,  0.01551285,  0.01807473,  0.01759212,  0.00160518,\n",
       "        0.017059  ,  0.        ,  0.05102365,  0.0116321 ,  0.01564352,\n",
       "        0.01362084,  0.02481682,  0.01350306,  0.        ,  0.01345387,\n",
       "       -0.01346922,  0.01375926,  0.0016225 ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The distance for house 0 is 0.06027470916295592\n",
      "The distance for house 1 is 0.08546881147643746\n",
      "The distance for house 2 is 0.06149946435279315\n",
      "The distance for house 3 is 0.05340273979294363\n",
      "The distance for house 4 is 0.05844484060170442\n",
      "The distance for house 5 is 0.059879215098128345\n",
      "The distance for house 6 is 0.05463140496775461\n",
      "The distance for house 7 is 0.05543108323614607\n",
      "The distance for house 8 is 0.052383627840220305\n",
      "The distance for house 9 is 0.05972359371398078\n"
     ]
    }
   ],
   "source": [
    "distance_test_0 = []\n",
    "for i in range(10):\n",
    "    diff = features_train[i] - features_test[0]\n",
    "    sqr_diff = sum(val**2 for val in diff)\n",
    "    distance = sqrt(sqr_diff)\n",
    "    distance_test_0.append(distance)\n",
    "    print(\"The distance for house {} is {}\".format(i,distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.052383627840220305"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(distance_test_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06\n"
     ]
    }
   ],
   "source": [
    "print(round(0.05972,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "Among the first 10 training houses, which house is the closest to the query house?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is computationally inefficient to loop over computing distances to all houses in our training dataset. Fortunately, many of the Numpy functions can be **vectorized**, applying the same operation over multiple values or vectors.  We now walk through this process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the following loop that computes the element-wise difference between the features of the query house (`features_test[0]`) and the first 3 training houses (`features_train[0:3]`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00 -3.87821276e-03 -1.20498190e-02 -1.05552733e-02\n",
      "  2.08673616e-04 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "  0.00000000e+00 -3.47633726e-03 -5.50336860e-03 -2.48168183e-02\n",
      " -1.63756198e-04  0.00000000e+00 -1.70254220e-05  1.29876855e-05\n",
      " -5.14364795e-03  6.69281453e-04]\n",
      "[ 0.00000000e+00 -3.87821276e-03 -4.51868214e-03 -2.26610387e-03\n",
      "  7.19763456e-04  0.00000000e+00  0.00000000e+00 -5.10236549e-02\n",
      "  0.00000000e+00 -3.47633726e-03  1.30705004e-03 -1.45830788e-02\n",
      " -1.91048898e-04  6.65082271e-02  4.23090220e-05  6.16364736e-06\n",
      " -2.89330197e-03  1.47606982e-03]\n",
      "[ 0.00000000e+00 -7.75642553e-03 -1.20498190e-02 -1.30002801e-02\n",
      "  1.60518166e-03 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "  0.00000000e+00 -5.21450589e-03 -8.32384500e-03 -2.48168183e-02\n",
      " -3.13866046e-04  0.00000000e+00  4.70885840e-05  1.56292487e-05\n",
      "  3.72914476e-03  1.64764925e-03]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print (features_train[i]-features_test[0])\n",
    "    # should print 3 vectors of length 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00000000e+00 -3.87821276e-03 -1.20498190e-02 -1.05552733e-02\n",
      "   2.08673616e-04 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "   0.00000000e+00 -3.47633726e-03 -5.50336860e-03 -2.48168183e-02\n",
      "  -1.63756198e-04  0.00000000e+00 -1.70254220e-05  1.29876855e-05\n",
      "  -5.14364795e-03  6.69281453e-04]\n",
      " [ 0.00000000e+00 -3.87821276e-03 -4.51868214e-03 -2.26610387e-03\n",
      "   7.19763456e-04  0.00000000e+00  0.00000000e+00 -5.10236549e-02\n",
      "   0.00000000e+00 -3.47633726e-03  1.30705004e-03 -1.45830788e-02\n",
      "  -1.91048898e-04  6.65082271e-02  4.23090220e-05  6.16364736e-06\n",
      "  -2.89330197e-03  1.47606982e-03]\n",
      " [ 0.00000000e+00 -7.75642553e-03 -1.20498190e-02 -1.30002801e-02\n",
      "   1.60518166e-03 -8.52950206e-03  0.00000000e+00 -5.10236549e-02\n",
      "   0.00000000e+00 -5.21450589e-03 -8.32384500e-03 -2.48168183e-02\n",
      "  -3.13866046e-04  0.00000000e+00  4.70885840e-05  1.56292487e-05\n",
      "   3.72914476e-03  1.64764925e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(features_train[0:3] - features_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# verify that vectorization works\n",
    "results = features_train[0:3] - features_test[0]\n",
    "print (results[0] - (features_train[0]-features_test[0]))\n",
    "# should print all 0's if results[0] == (features_train[0]-features_test[0])\n",
    "print (results[1] - (features_train[1]-features_test[0]))\n",
    "# should print all 0's if results[1] == (features_train[1]-features_test[0])\n",
    "print (results[2] - (features_train[2]-features_test[0]))\n",
    "# should print all 0's if results[2] == (features_train[2]-features_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform 1-nearest neighbor regression\n",
    "\n",
    "Now that we have the element-wise differences, it is not too hard to compute the Euclidean distances between our query house and all of the training houses. First, write a single-line expression to define a variable `diff` such that `diff[i]` gives the element-wise difference between the features of the query house and the `i`-th training house."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def euclidean_distance(feature_matrix,query_vector):\n",
    "    diff = feature_matrix-query_vector\n",
    "    distance = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0033070590284564457\n",
      "0.0033070590284564453\n"
     ]
    }
   ],
   "source": [
    "diff = features_train - features_test[0]\n",
    "print (np.sum(diff**2, axis=1)[15]) # take sum of squares across each row, and print the 16th sum\n",
    "print (np.sum(diff[15]**2)) # print the sum of squares for the 16th row -- should be same as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = euclidean_distance(features_train ,features_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.023708232416678195"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTIONS ***\n",
    "\n",
    "1.  Take the query house to be third house of the test set (`features_test[2]`).  What is the index of the house in the training set that is closest to this query house?\n",
    "2.  What is the predicted value of the query house based on 1-nearest neighbor regression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicted_value(distance_vector,output_vector):\n",
    "    min_dis = min(distance_vector)\n",
    "    min_dis_index = np.where(distance_vector == min_dis)\n",
    "    predicted_value = output_vector[min_dis_index]\n",
    "    return(min_dis_index, predicted_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038768105218265616"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((array([3758]),), array([635000.]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_value(distance,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_test_2 = euclidean_distance(features_train,features_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_test_2,predicted_test_2 = predicted_value(distance_test_2,output_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([382]),) [249000.]\n"
     ]
    }
   ],
   "source": [
    "print(index_test_2,predicted_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform k-nearest neighbor regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-nearest neighbors, we need to find a *set* of k houses in the training set closest to a given query house. We then make predictions based on these k nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch k-nearest neighbors\n",
    "\n",
    "Using the functions above, implement a function that takes in\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses; and\n",
    " * the feature vector of the query house\n",
    " \n",
    "and returns the indices of the k closest training houses. For instance, with 2-nearest neighbor, a return value of [5, 10] would indicate that the 6th and 11th training houses are closest to the query house.\n",
    "\n",
    "**Hint**: Look at the [documentation for `np.argsort`](http://docs.scipy.org/doc/numpy/reference/generated/numpy.argsort.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbour_index(k,feature_matrix,query_vector):\n",
    "    diff = feature_matrix-query_vector\n",
    "    distance = np.sqrt(np.sum(diff**2, axis=1))\n",
    "    distance_sorted_index =  np.argsort(distance)\n",
    "    return distance_sorted_index[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 382, 1149, 4087, 3142])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest_neighbour_index(4,features_train,features_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_value = output_train[[ 382, 1149, 4087, 3142]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[249000. 477000. 499950. 430000.]\n",
      "413987.5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "413987.5"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(predicted_value)\n",
    "print(np.average(predicted_value))\n",
    "(249000 + 477000 + 499950 + 430000)/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a single prediction by averaging k nearest neighbor outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to find the k-nearest neighbors, write a function that predicts the value of a given query house. **For simplicity, take the average of the prices of the k nearest neighbors in the training set**. The function should have the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature vector of the query house, whose price we are predicting.\n",
    " \n",
    "The function should return a predicted value of the query house.\n",
    "\n",
    "**Hint**: You can extract multiple items from a Numpy array using a list of indices. For instance, `output_train[[6, 10]]` returns the prices of the 7th and 11th training houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def k_nearest_neighbour(k,feature_matrix,output_vector,query_set):\n",
    "    diff = feature_matrix-query_set\n",
    "    distance = np.sqrt(np.sum(diff**2 , axis =1))\n",
    "    distance_sorted_index = np.argsort(distance)\n",
    "    k_distance_index = distance_sorted_index[0:k]\n",
    "    predicted_values = output_vector[k_distance_index]\n",
    "    return np.average(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413987.5"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_nearest_neighbour(4,features_train,output_train,features_test[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make multiple predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function to predict the value of *each and every* house in a query set. (The query set can be any subset of the dataset, be it the test set or validation set.) The idea is to have a loop where we take each house in the query set as the query house and make a prediction for that specific house. The new function should take the following parameters:\n",
    " * the value of k;\n",
    " * the feature matrix for the training houses;\n",
    " * the output values (prices) of the training houses; and\n",
    " * the feature matrix for the query set.\n",
    " \n",
    "The function should return a set of predicted values, one for each house in the query set.\n",
    "\n",
    "**Hint**: To get the number of houses in the query set, use the `.shape` field of the query features matrix. See [the documentation](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ndarray.shape.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.zeros(10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_multiple(k,feature_matrix,output_vector,query_vector):\n",
    "    length = query_vector.shape[0]\n",
    "    predicted_vector = np.zeros(length)\n",
    "    for i in range(length):\n",
    "        predicted_vector[i] = k_nearest_neighbour(k,feature_matrix,output_vector,query_vector[i])\n",
    "    return predicted_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([413987.5])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_multiple(4,features_train,output_train,features_test[2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 18)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_test[1:2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** QUIZ QUESTION ***\n",
    "\n",
    "Make predictions for the first 10 houses in the test set using k-nearest neighbors with `k=10`. \n",
    "\n",
    "1. What is the index of the house in this query set that has the lowest predicted value? \n",
    "2. What is the predicted value of this house?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_10 = knn_multiple(10,features_train,output_train,features_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([881300. , 431860. , 460595. , 430200. , 766750. , 667420. ,\n",
       "       350032. , 512800.7, 484000. , 457235. ])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "350032.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(predicted_10) ## 6th index , 7th house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing the best value of k using a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There remains a question of choosing the value of k to use in making predictions. Here, we use a validation set to choose this value. Write a loop that does the following:\n",
    "\n",
    "* For `k` in [1, 2, ..., 15]:\n",
    "    * Makes predictions for each house in the VALIDATION set using the k-nearest neighbors from the TRAINING set.\n",
    "    * Computes the RSS for these predictions on the VALIDATION set\n",
    "    * Stores the RSS computed above in `rss_all`\n",
    "* Report which `k` produced the lowest RSS on VALIDATION set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_validation(k_values, features_matrix, output_vector, query_vector, query_output):\n",
    "    rss_all = []\n",
    "    size_output = query_vector.shape[0]\n",
    "    for k in range(1,k_values+1):\n",
    "        predicted_valid = knn_multiple(k,features_matrix,output_vector,query_vector)\n",
    "        residuals = predicted_valid - query_output\n",
    "        rss = sum(val**2 for val in residuals)\n",
    "        #print(rss)\n",
    "        rss_all.append(rss)\n",
    "        #print(predicted_valid)\n",
    "    return rss_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[386403493125.0,\n",
       " 291026272975.0,\n",
       " 373188146322.22217,\n",
       " 243546459212.5,\n",
       " 216570186696.0,\n",
       " 215316087984.69443,\n",
       " 208838116478.55096,\n",
       " 203815339999.20312,\n",
       " 205893419993.19754,\n",
       " 227424136694.49]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_validation(10,features_train,output_train,features_test[0:10],output_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_rss = knn_validation(15,features_train,output_train,features_valid,output_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[105453830251561.0,\n",
       " 83445073504025.5,\n",
       " 72692096019202.8,\n",
       " 71946721652091.69,\n",
       " 69846517419718.586,\n",
       " 68899544353181.09,\n",
       " 68341973450051.055,\n",
       " 67361678735491.5,\n",
       " 68372727958976.336,\n",
       " 69335048668556.7,\n",
       " 69523855215598.875,\n",
       " 69049969587246.45,\n",
       " 70011254508263.625,\n",
       " 70908698869034.44,\n",
       " 71106928385945.36]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the performance as a function of `k`, plot the RSS on the VALIDATION set for each considered `k` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67361678735491.5"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(valid_rss)   ## K =8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1196aa7f0>]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "kvals = range(1, 16)\n",
    "plt.plot(kvals, valid_rss,'bo-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***QUIZ QUESTION ***\n",
    "\n",
    "What is the RSS on the TEST data using the value of k found above?  To be clear, sum over all houses in the TEST set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[189300603178121.0,\n",
       " 162969655347954.25,\n",
       " 149008586983832.44,\n",
       " 137914467769569.0,\n",
       " 132270467766797.36,\n",
       " 132736445589544.89,\n",
       " 131757081714412.03,\n",
       " 133118823551516.81]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " knn_validation(8,features_train,output_train,features_test,output_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " ##133118823551516.81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3E+14'"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:.1E}\".format((133118823551516.81))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
