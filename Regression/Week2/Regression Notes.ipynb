{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso and Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For the longest time, I never really understood the difference between Lasso and Ridge Regularization aside from the fact that the Lasso took sum of the absolute value of the coefficients and that the Ridge took the sum of the square of coefficients.\n",
    "##### I knew that the purpose of both were to prevent overfitting of a model by penalizing complexity of the model and reducing the variance, but that was to the extent in which I understood Lasso and Ridge Regularization.\n",
    "##### However, after class today, I learned the underlying difference between what taking the absolute value of coefficients and taking the square of coefficients actually meant in practice.\n",
    "##### By reducing the sum of absolute values of the coefficients, what Lasso Regularization (L1 Norm) does is to reduce the number of features in the model altogether to predict the target variable.\n",
    "##### On the other hand, by reducing the sum of square of coefficients, Ridge Regularization (L2 Norm) doesn’t necessarily reduce the number of features per se, but rather reduces the magnitude/impact that each features has on the model by reducing the coefficient value.\n",
    "##### So simply put, both regularization does indeed prevent the model from overfitting, \n",
    "##### but I would like to think of Lasso Regularization as reducing the quantity of features \n",
    "##### while Ridge Regularization as reducing the quality of features. In essence, both types of \n",
    "##### reductions are needed, and therefore it makes much more sense why ElasticNet (combination of Lasso and Ridge Regularization) would be the ideal type of regularization to perform on a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting is a phenomenon that occurs when a machine learning or statistics model is tailored to a particular dataset and is unable to generalise to other datasets. This usually happens in complex models, like deep neural networks.\n",
    "Regularisation is a process of introducing additional information in order to prevent overfitting. The focus for this article is L1 and L2 regularisation.\n",
    "There are many explanations out there but honestly, they are a little too abstract, and I’d probably forget them and end up visiting these pages, only to forget again. In this article, I will be sharing with you some intuitions why L1 and L2 work by explaining using gradient descent. Gradient descent is simply a method to find the ‘right’ coefficients through iterative updates using the value of the gradient. (This article shows how gradient descent can be used in a simple linear regression.)\n",
    "Content\n",
    "0) What’s L1 and L2?\n",
    "1) Model\n",
    "2) Loss Functions\n",
    "3) Gradient Descent\n",
    "4) How is overfitting prevented?\n",
    "Let’s go!\n",
    "0) What’s L1 and L2?\n",
    "L1 and L2 regularisation owes its name to L1 and L2 norm of a vector w respectively. Here’s a primer on norms:\n",
    "\n",
    "1-norm (also known as L1 norm)\n",
    "\n",
    "2-norm (also known as L2 norm or Euclidean norm)\n",
    "\n",
    "p-norm\n",
    "A linear regression model that implements L1 norm for regularisation is called lasso regression, and one that implements (squared) L2 norm for regularisation is called ridge regression. To implement these two, note that the linear regression model stays the same:\n",
    "\n",
    "but it is the calculation of the loss function that includes these regularisation terms:\n",
    "\n",
    "Loss function with no regularisation\n",
    "\n",
    "Loss function with L1 regularisation\n",
    "\n",
    "Loss function with L2 regularisation\n",
    "Note: Strictly speaking, the last equation (ridge regression) is a loss function with squared L2 norm of the weights (notice the absence of the square root). (Thank you Max Pechyonkin for highlighting this!)\n",
    "The regularisation terms are ‘constraints’ by which an optimisation algorithm must ‘adhere to’ when minimising the loss function, apart from having to minimise the error between the true y and the predicted ŷ.\n",
    "1) Model\n",
    "Let’s define a model to see how L1 and L2 work. For simplicity, we define a simple linear regression model ŷ with one independent variable.\n",
    "\n",
    "Here I have used the deep learning conventions w (‘weight’) and b (‘bias’).\n",
    "In practice, simple linear regression models are not prone to overfitting. As mentioned in the introduction, deep learning models are more susceptible to such problems due to their model complexity.\n",
    "As such, do note that the expressions used in this article are easily extended to more complex models, not limited to linear regression.\n",
    "2) Loss Functions\n",
    "To demonstrate the effect of L1 and L2 regularisation, let’s fit our linear regression model using 3 different loss functions/objectives:\n",
    "L\n",
    "L1\n",
    "L2\n",
    "Our objective is to minimise these different losses.\n",
    "2.1) Loss function with no regularisation\n",
    "We define the loss function L as the squared error, where error is the difference between y (the true value) and ŷ (the predicted value).\n",
    "\n",
    "Let’s assume our model will be overfitted using this loss function.\n",
    "2.2) Loss function with L1 regularisation\n",
    "Based on the above loss function, adding an L1 regularisation term to it looks like this:\n",
    "\n",
    "where the regularisation parameter λ > 0 is manually tuned. Let’s call this loss function L1. Note that |w| is differentiable everywhere except when w=0, as shown below. We will need this later.\n",
    "\n",
    "2.3) Loss function with L2 regularisation\n",
    "Similarly, adding an L2 regularisation term to L looks like this:\n",
    "\n",
    "where again, λ > 0.\n",
    "3) Gradient Descent\n",
    "Now, let’s solve the linear regression model using gradient descent optimisation based on the 3 loss functions defined above. Recall that updating the parameter w in gradient descent is as follows:\n",
    "\n",
    "Let’s substitute the last term in the above equation with the gradient of L, L1 and L2 w.r.t. w.\n",
    "L:\n",
    "\n",
    "L1:\n",
    "\n",
    "L2:\n",
    "\n",
    "4) How is overfitting prevented?\n",
    "From here onwards, let’s perform the following substitutions on the equations above (for better readability):\n",
    "η = 1,\n",
    "H = 2x(wx+b-y)\n",
    "which give us\n",
    "L:\n",
    "\n",
    "L1:\n",
    "\n",
    "L2:\n",
    "\n",
    "4.1) With vs. Without Regularisation\n",
    "Observe the differences between the weight updates with the regularisation parameter λ and without it. Here are some intuitions.\n",
    "Intuition A:\n",
    "Let’s say with Equation 0, calculating w-H gives us a w value that leads to overfitting. Then, intuitively, Equations {1.1, 1.2 and 2} will reduce the chances of overfitting because introducing λ makes us shift away from the very w that was going to cause us overfitting problems in the previous sentence.\n",
    "Intuition B:\n",
    "Let’s say an overfitted model means that we have a w value that is perfect for our model. ‘Perfect’ meaning if we substituted the data (x) back in the model, our prediction ŷ will be very, very close to the true y. Sure, it’s good, but we don’t want perfect. Why? Because this means our model is only meant for the dataset which we trained on. This means our model will produce predictions that are far off from the true value for other datasets. So we settle for less than perfect, with the hope that our model can also get close predictions with other data. To do this, we ‘taint’ this perfect w in Equation 0 with a penalty term λ. This gives us Equations {1.1, 1.2 and 2}.\n",
    "Intuition C:\n",
    "Notice that H (as defined here) is dependent on the model (w and b) and the data (x and y). Updating the weights based only on the model and data in Equation 0 can lead to overfitting, which leads to poor generalisation. On the other hand, in Equations {1.1, 1.2 and 2}, the final value of w is not only influenced by the model and data, but also by a predefined parameter λ which is independent of the model and data. Thus, we can prevent overfitting if we set an appropriate value of λ, though too large a value will cause the model to be severely underfitted.\n",
    "Intuition D:\n",
    "Edden Gerber (thanks!) has provided an intuition about the direction toward which our solution is being shifted. Have a look in the comments: https://medium.com/@edden.gerber/thanks-for-the-article-1003ad7478b2\n",
    "4.2) L1 vs. L2\n",
    "We shall now focus our attention to L1 and L2, and rewrite Equations {1.1, 1.2 and 2} by rearranging their λ and H terms as follows:\n",
    "L1:\n",
    "\n",
    "L2:\n",
    "\n",
    "Compare the second term of each of the equation above. Apart from H, the change in w depends on the ±λ term or the -2λw term, which highlight the influence of the following:\n",
    "sign of current w (L1, L2)\n",
    "magnitude of current w (L2)\n",
    "doubling of the regularisation parameter (L2)\n",
    "While weight updates using L1 are influenced by the first point, weight updates from L2 are influenced by all aspects. While I have made this comparison just based on the iterative equation update, please note that this does not mean that one is ‘better’ than the other.\n",
    "For now, let’s see below how a regularisation effect from L1 can be attained just by the sign of the current w.\n",
    "4.3) L1’s effect on pushing towards 0 (sparsity)\n",
    "Take a look at L1 in Equation 3.1. If w is positive, the regularisation parameter λ>0 will push w to be less positive, by subtracting λ from w. Conversely in Equation 3.2, if w is negative, λ will be added to w, pushing it to be less negative. Hence, this has the effect of pushing w towards 0.\n",
    "This is of course pointless in a 1-variable linear regression model, but will prove its prowess to ‘remove’ useless variables in multivariate regression models. You can also think of L1 as reducing the number of features in the model altogether. Here is an arbitrary example of L1 trying to ‘push’ some variables in a multivariate linear regression model:\n",
    "\n",
    "So how does pushing w towards 0 help in overfitting in L1 regularisation? As mentioned above, as w goes to 0, we are reducing the number of features by reducing the variable importance. In the equation above, we see that x_2, x_4 and x_5 are almost ‘useless’ because of their small coefficients, hence we can remove them from the equation. This in turn reduces the model complexity, making our model simpler. A simpler model can reduce the chances of overfitting.\n",
    "Note\n",
    "While L1 has the influence of pushing weights towards 0 and L2 does not, this does not imply that weights are not able to reach close to 0 due to L2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias Variance Tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we discuss model prediction, it’s important to understand prediction errors (bias and variance). There is a tradeoff between a model’s ability to minimize bias and variance. Gaining a proper understanding of these errors would help us not only to build accurate models but also to avoid the mistake of overfitting and underfitting.\n",
    "So let’s start with the basics and see how they make difference to our machine learning Models.\n",
    "What is bias?\n",
    "Bias is the difference between the average prediction of our model and the correct value which we are trying to predict. Model with high bias pays very little attention to the training data and oversimplifies the model. It always leads to high error on training and test data.\n",
    "What is variance?\n",
    "Variance is the variability of model prediction for a given data point or a value which tells us spread of our data. Model with high variance pays a lot of attention to training data and does not generalize on the data which it hasn’t seen before. As a result, such models perform very well on training data but has high error rates on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Gaussian Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://mccormickml.com/2014/02/26/kernel-regression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
